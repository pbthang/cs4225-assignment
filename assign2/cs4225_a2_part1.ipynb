{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pbthang/cs4225-assignment/blob/main/assign2/cs4225_a2_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JdFpIxeJTyh"
      },
      "source": [
        "# Setup Spark\n",
        "# ===============\n",
        "# Installing Spark needs to be done once each time you re-open this notebook. It should take around 10-30 seconds.\n",
        "# ===============\n",
        "# install java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
        "\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.3.1-bin-hadoop3.tgz\n",
        "\n",
        "# set your spark folder to your system path environment.\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop3\"\n",
        "\n",
        "# install findspark using pip\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MtZV07rJcTA"
      },
      "source": [
        "# After downloading dataset, you should have a file \"system.log\" in your Files (click the folder icon in the left sidebar)\n",
        "!wget https://bhooi.github.io/teaching/cs4225/bomb/part1/system.log\n",
        "df = spark.read.text(\"system.log\").repartition(1).cache()\n",
        "df.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10F1FGrbKLXh"
      },
      "source": [
        "# Write your code for processing the data here.\n",
        "\n",
        "df = df.filter(~df.value.contains(\"alpha\"))\n",
        "df = df.filter(~df.value.contains(\"[notice]\"))\n",
        "df = df.filter(~df.value.contains(\"[error]\")).cache()\n",
        "df.toPandas()\n",
        "df_with_pw = df.filter(df.value.contains(\"invalid user\"))\n",
        "df_with_pw.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yE9MkLmqruSn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}